{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[4.7901e-01, 7.5752e-01, 6.8014e-01,  ..., 8.4620e-01,\n          2.1694e-02, 5.4258e-01],\n         [7.8639e-01, 5.9219e-01, 1.7673e-01,  ..., 7.3143e-01,\n          9.5931e-01, 8.2458e-01],\n         [4.7521e-01, 5.0097e-01, 8.4320e-01,  ..., 6.9292e-01,\n          6.4552e-04, 2.1447e-02],\n         ...,\n         [2.5530e-01, 4.6809e-01, 3.9989e-01,  ..., 2.9638e-01,\n          3.7990e-01, 8.6260e-01],\n         [7.6159e-01, 3.1584e-01, 4.9473e-01,  ..., 6.8497e-01,\n          3.4244e-01, 7.3588e-01],\n         [2.0436e-01, 4.2053e-01, 7.2203e-01,  ..., 7.8613e-01,\n          3.3993e-01, 2.3390e-01]],\n\n        [[1.1662e-02, 4.4464e-02, 1.8670e-01,  ..., 3.9988e-01,\n          9.7095e-01, 4.6521e-01],\n         [4.4582e-01, 3.2129e-01, 5.4050e-01,  ..., 6.8167e-01,\n          6.5012e-01, 9.0964e-01],\n         [1.5230e-01, 7.2412e-01, 3.6466e-01,  ..., 4.9376e-01,\n          2.3578e-01, 6.6712e-01],\n         ...,\n         [5.8602e-01, 6.3257e-01, 4.3618e-01,  ..., 3.9502e-01,\n          2.9734e-01, 6.0082e-01],\n         [1.8132e-01, 3.1876e-01, 3.3014e-01,  ..., 5.4027e-01,\n          2.3846e-01, 7.1156e-01],\n         [1.6300e-01, 9.5332e-01, 4.7021e-01,  ..., 1.7328e-01,\n          3.5772e-01, 6.0922e-01]],\n\n        [[5.6003e-01, 5.1608e-01, 7.8431e-01,  ..., 5.0001e-01,\n          5.6579e-02, 9.3194e-02],\n         [6.6300e-01, 9.3246e-01, 4.3947e-01,  ..., 9.1509e-01,\n          6.2881e-01, 4.6898e-03],\n         [1.1188e-02, 1.4493e-01, 6.7278e-01,  ..., 8.6027e-01,\n          9.7402e-01, 1.0540e-01],\n         ...,\n         [3.3111e-01, 8.5472e-01, 1.8392e-01,  ..., 8.8597e-01,\n          1.4783e-01, 5.5444e-01],\n         [2.9648e-01, 3.0812e-01, 2.5899e-01,  ..., 8.3397e-01,\n          5.1680e-01, 8.6855e-02],\n         [7.1699e-02, 8.2259e-01, 3.8950e-01,  ..., 2.7719e-02,\n          7.6768e-01, 1.3756e-02]],\n\n        ...,\n\n        [[5.7963e-01, 6.7677e-01, 8.5535e-01,  ..., 6.5812e-01,\n          7.1369e-01, 3.2642e-01],\n         [3.5116e-01, 9.8820e-02, 4.8020e-02,  ..., 6.8807e-01,\n          1.3527e-02, 9.8416e-01],\n         [6.9808e-01, 3.1427e-01, 4.5854e-01,  ..., 8.0594e-01,\n          6.8717e-01, 5.9021e-01],\n         ...,\n         [9.1153e-01, 1.8887e-01, 1.7394e-01,  ..., 4.0461e-01,\n          6.3397e-01, 3.2045e-01],\n         [2.5788e-01, 6.7362e-01, 6.2165e-01,  ..., 8.1885e-01,\n          5.7694e-02, 4.2202e-01],\n         [6.5363e-01, 1.5645e-01, 6.0417e-01,  ..., 8.5684e-01,\n          5.1761e-01, 5.2833e-01]],\n\n        [[2.1920e-01, 2.3813e-01, 3.7593e-01,  ..., 9.0114e-01,\n          3.5306e-01, 9.6817e-01],\n         [7.4340e-01, 2.5918e-02, 6.4667e-01,  ..., 5.5207e-01,\n          2.0199e-01, 4.4518e-01],\n         [8.0892e-01, 7.2091e-01, 6.5975e-01,  ..., 7.4078e-01,\n          2.3476e-01, 3.4619e-01],\n         ...,\n         [1.9038e-01, 5.4982e-01, 3.5327e-01,  ..., 7.4557e-01,\n          1.0391e-01, 7.0681e-01],\n         [9.4558e-01, 4.5675e-01, 4.8530e-01,  ..., 4.8852e-01,\n          4.5704e-01, 6.8618e-01],\n         [2.3541e-01, 9.4416e-01, 7.2254e-01,  ..., 1.2732e-01,\n          9.4516e-01, 9.0727e-01]],\n\n        [[8.3195e-01, 3.6181e-01, 1.5984e-01,  ..., 6.0881e-01,\n          7.6656e-02, 4.0346e-01],\n         [2.9125e-01, 5.6161e-01, 2.7568e-01,  ..., 4.4715e-01,\n          4.7458e-01, 2.4254e-01],\n         [6.1932e-01, 7.2721e-01, 2.9943e-01,  ..., 1.9679e-02,\n          7.1780e-01, 4.9397e-01],\n         ...,\n         [1.6814e-01, 9.0630e-01, 5.8367e-01,  ..., 1.0450e-01,\n          5.4635e-01, 5.3253e-01],\n         [7.8413e-01, 3.2905e-02, 9.5997e-01,  ..., 9.5619e-01,\n          9.2519e-02, 2.2851e-01],\n         [1.2104e-01, 5.7542e-01, 1.5384e-01,  ..., 3.5126e-01,\n          5.6739e-01, 9.7593e-01]]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([8, 100, 10]).detach()\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(8)\n",
    "y = (y > 0.5).int()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.first_layer = nn.Linear(1000, 50)\n",
    "        self.second_layer = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=2)\n",
    "        x = nn.functional.relu(self.first_layer(x))\n",
    "        x = self.second_layer(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mlp= MLP()\n",
    "output = mlp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1486],\n        [0.1711],\n        [0.0181],\n        [0.1344],\n        [0.0982],\n        [0.0463],\n        [0.1445],\n        [0.0676]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(4, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "embedding = Embedding()\n",
    "\n",
    "embedding_input = torch.tensor([[0, 1, 0], [2, 3, 3]])\n",
    "embedding_output = embedding(embedding_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 100])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(10, 15, num_layers=2, bidirectional=True, dropout=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        return output, hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "permute_x = x.permute([1, 0, 2])\n",
    "lstm = LSTM()\n",
    "output_lstm1, output_lstm2, output_lstm3 = lstm(permute_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.0217, -0.0607, -0.0139,  ...,  0.0726,  0.1714,  0.0123],\n         [-0.0029, -0.0445,  0.0026,  ...,  0.0772,  0.1370,  0.0076],\n         [ 0.0126, -0.0461, -0.0166,  ...,  0.0755,  0.1751,  0.0287],\n         ...,\n         [-0.0009, -0.0458,  0.0008,  ...,  0.0791,  0.1363,  0.0071],\n         [-0.0030, -0.0640,  0.0005,  ...,  0.0662,  0.1623,  0.0338],\n         [ 0.0040, -0.0584, -0.0054,  ...,  0.0804,  0.1635,  0.0176]],\n\n        [[ 0.0169, -0.0913, -0.0146,  ...,  0.0778,  0.1655,  0.0162],\n         [ 0.0036, -0.0858, -0.0125,  ...,  0.0838,  0.1564,  0.0172],\n         [ 0.0087, -0.0730, -0.0316,  ...,  0.0786,  0.1705,  0.0228],\n         ...,\n         [ 0.0047, -0.0842, -0.0157,  ...,  0.0706,  0.1443,  0.0248],\n         [ 0.0017, -0.0853,  0.0046,  ...,  0.0740,  0.1711,  0.0390],\n         [ 0.0193, -0.0839, -0.0191,  ...,  0.0789,  0.1558,  0.0103]],\n\n        [[ 0.0313, -0.0988, -0.0400,  ...,  0.0658,  0.1694,  0.0407],\n         [ 0.0078, -0.1100, -0.0295,  ...,  0.0854,  0.1631,  0.0176],\n         [ 0.0181, -0.0858, -0.0480,  ...,  0.0753,  0.1719,  0.0406],\n         ...,\n         [ 0.0052, -0.0974, -0.0195,  ...,  0.0735,  0.1541,  0.0336],\n         [ 0.0174, -0.1072, -0.0204,  ...,  0.0808,  0.1830,  0.0225],\n         [ 0.0141, -0.0991, -0.0250,  ...,  0.0793,  0.1696,  0.0190]],\n\n        ...,\n\n        [[ 0.0005, -0.1242, -0.0400,  ...,  0.0400,  0.1515,  0.0307],\n         [ 0.0009, -0.1129, -0.0455,  ...,  0.0392,  0.1428,  0.0117],\n         [ 0.0270, -0.1313, -0.0598,  ...,  0.0403,  0.1665,  0.0124],\n         ...,\n         [ 0.0076, -0.1156, -0.0665,  ...,  0.0411,  0.1630,  0.0413],\n         [-0.0077, -0.1267, -0.0163,  ...,  0.0443,  0.1552,  0.0074],\n         [ 0.0163, -0.1218, -0.0501,  ...,  0.0475,  0.1415,  0.0207]],\n\n        [[ 0.0042, -0.1318, -0.0412,  ...,  0.0249,  0.1410,  0.0411],\n         [-0.0031, -0.1149, -0.0466,  ...,  0.0281,  0.1293,  0.0133],\n         [ 0.0175, -0.1188, -0.0638,  ...,  0.0194,  0.1452,  0.0210],\n         ...,\n         [ 0.0022, -0.1126, -0.0608,  ...,  0.0282,  0.1478,  0.0421],\n         [-0.0030, -0.1196, -0.0416,  ...,  0.0255,  0.1458,  0.0264],\n         [ 0.0119, -0.1102, -0.0475,  ...,  0.0253,  0.1292,  0.0325]],\n\n        [[ 0.0118, -0.1140, -0.0451,  ...,  0.0117,  0.0922,  0.0210],\n         [-0.0040, -0.1180, -0.0375,  ...,  0.0103,  0.0992,  0.0181],\n         [ 0.0221, -0.1103, -0.0552,  ...,  0.0093,  0.1004,  0.0087],\n         ...,\n         [ 0.0101, -0.1126, -0.0616,  ...,  0.0080,  0.1091,  0.0341],\n         [-0.0072, -0.1120, -0.0437,  ...,  0.0123,  0.1027,  0.0215],\n         [ 0.0052, -0.1138, -0.0467,  ...,  0.0114,  0.0900,  0.0102]]],\n       grad_fn=<CatBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lstm1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(100, 50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv1d(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "conv = Conv()\n",
    "output = conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 50, 9])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 100, 10])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}